= Database Infra
:toc:
:keywords: ElephantSQL,PostgreSQL,Database

== ElephantSQL Postgresql as a Service

In search of a free DB I found https://www.elephantsql.com/[www.elephantsql.com] which provide
free plans for DBs up to *20MB* and *5 concurrent connections* which was perfectly sufficient for my project.
Of course you can also host your own DB or use AWS managed https://aws.amazon.com/rds/?nc1=h_ls[RDS] service

== Create local database
[source,shell script]
----
$ psql
select version();
PostgreSQL 11.5 (Ubuntu 11.5-3.pgdg18.04+1)
create database angkor;
create user angkor;
grant all privileges on database angkor to angkor;

$  psql -U rootuser angkor
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

$  psql -U angkor -d angkor -f import.sql
----

== Get all backups via ElephantSQL API

[source,shell script]
----
curl -u :xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxxx https://api.elephantsql.com/api/backup?db=my-db
----

== Drop all tables w/o dropping schema

As you don't own the public schema in ElefantSQL, you can't drop the entire schema but
https://stackoverflow.com/questions/3327312/how-can-i-drop-all-the-tables-in-a-postgresql-database[this] discussion helps

[source,sql]
----
SELECT
  'DROP TABLE IF EXISTS "' || tablename || '" CASCADE;'
from
  pg_tables WHERE schemaname = 'public';
----

== Useful SQL Statements

=== Disable sequal scan to test if index is used
To test, whether the index can be used, disable sequential scans in a test session (for debugging only!):

[source,sql]
----
SET enable_seqscan = OFF;
----

=== Get distinct array values with count

`select unnest(tags) as tag, count(*) from dish group by tag order by count(*) desc;`

.Top 25 Tags - based on : https://tapoueh.org/blog/2018/04/postgresql-data-types-arrays/[postgresql-data-types-arrays]
[source,sql]
----
-- explain (analyze, verbose, costs off, buffers)
select tag, count(*) as count
from place, unnest(tags) as t(tag)
group by tag
order by count desc
limit 25;
----

----
 tag         ‚îÇ count
 ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
 #beach      ‚îÇ 17964
 #snow       ‚îÇ  4776
----

.How many dishes are considered veggy?
[source,sql]
----
-- explain (analyze, verbose, costs off, buffers)
select count(*)
from dish
where tags @> array['veggy'];

----

.Increment Reminder data for all notes by 6 month
----
update note set due_date = due_date + INTERVAL '6 month'
where due_date is not null and status != 'CLOSED'
----

== Switch to an older Postgres Version after `brew update` (e.g. 13=>12)

homebrew will always try to use the latest major postgres version, if you want to keep an old version to keep it consistent with your staging / prod db, you may have to re-link after running `brew update`

[source,shell script]
----
$ brew info postgresql
postgresql: stable 13.3 (bottled), HEAD
$ brew search postgres
$ brew install postgresql@12
$ brew ublink postgresql
$ brew link postgresql@12
Linking /usr/local/Cellar/postgresql@12/12.7... 456 symlinks created.
----


== Upgrade Postgresql Major Version and migrate DBs (2023-11)

Check for exiting üç∫ brew formulae:

----
$ brew search postgresql
postgresql@11       postgresql@12 ‚úî     postgresql@13       postgresql@15 ‚úî
----

Install new version parallel to existing version

----
$ brew install postgresql@15
----

The formula creates a default database cluster with locale 'C', see https://www.postgresql.org/docs/15/app-initdb.html[app-initdb  create a new db cluster]. If you plan to migrate the existing db directory from the old version, make sure the new db has the same lc-collate value, or you get messages such as 'lc_collate values for database "template1" do not match:  old "de_DE.UTF-8", new "C"''. If necessary, you can wipe the `pgdata` directory and re-init it with new settings, e.g.

----
$ initdb --pgdata="$HOME/.pgdata16"  \
  --encoding=UTF8 --lc-collate=en_EN.UTF-8
----

Adapt your aliases and PATH to point to the new version

.Files .bashrc resp. .bash_aliases
----
export PGVERSION=16
export PGDATA="$HOME"/.pgdata$PGVERSION
alias pg_run="echo Logging to $PGDATA/pg.log; pg_ctl -D $PGDATA --log=$PGDATA/pg.log start"
alias pg_stop="echo Logging to $PGDATA/pg.log; pg_ctl -D $PGDATA --log=$PGDATA/pg.log stop"

export PATH="/usr/local/opt/postgresql@${PGVERSION}/bin:$PATH"
----

Different ways to start postgresql as a background service
----
$ brew services start postgresql@16
$ LC_ALL="C" /usr/local/opt/postgresql@16/bin/postgres -D /usr/local/var/postgresql@16
----

Start migration from old data directory to new Path
(if successful, you can wipe the old directory unless you want to keep multiple postgresql versions in parallel):

[source,shellscript]
----
$ pg_upgrade --old-datadir $HOME/.pgdata15 --new-datadir $HOME/.pgdata16 \
  --old-bindir /opt/homebrew/opt/postgresql@15/bin --new-bindir /opt/homebrew/opt/postgresql@16/bin
----

== ElephantSQL: Upgrade Postgres, Restore DB from Backup

ElephantSQL doesn't seem to provide a means to upgrade the instance "in-place".
But it's easy to create a new database in parallel (which will have the latest available version) and migrate the data
to the new db:

* Check current major version in the Web Console
+
----
select version()
PostgreSQL 13.9 (Ubuntu 13.9-1.pgdg20.04+1) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 9.4.0(...)
----
* Create new database in Web Console named <current-db>-new (to be renamed after migration). Again, check the version anf if it's not a newer one or even older there's no point to continue
* Select your existing database, go to backups
* Backup *database now*, once available download <dbname>.<timestamp>.sql.lzo
* Uncompress with `lzop -cd <dbname>.<timestamp>.sql.lzo > dump.sql` (lzop can be installed with brew)
* Open dump.sql, replace older user (which is also the default db name such as 'nldhexx')
with the new username (e.g. `sed  's/old_name/new_name/g' dump.sql >dump2.sql`)
* If the new db is not empty (e.g. b/c you did multiple test runs), drop tables and types first (if you want your import error-free)
+
----
DROP TABLE IF EXISTS "event" CASCADE;
DROP TYPE IF EXISTS auth_scope;
(...)
----
* run `psql` to restore, and check version in new db. you can ignore erros such as `must be owner of extension btree_gist`
since the extensions are automatically created when you create a new instance!
+
.Import sql dump
----
PGPASSWORD=<yourpassword> psql --file=dump2.sql --username=<newuser> --host=<host>.db.elephantsql.com --port=5432
----
+
.Verify (show version)
----
PGPASSWORD=<yourpassword> psql  --username=<newuser> --host=<host>.db.elephantsql.com  --port=5432 -c "SELECT VERSION()"

 PostgreSQL 13.4 (Ubuntu 13.4-4.pgdg20.04+1) on x86_64-pc-linux-gnu (...)
----

* edit `terraform/terraform.tfvars` and update db_url, db_username, db_password and db_api_key (make sure .env gets updates for docker-compose), apply, trigger docker-compose to restart the containers, check if the new url applies and the app is running.
+
----
$ docker logs angkor-api | grep Database
2021-11-13 09:55:00Z  INFO o.f.c.i.database.base.BaseDatabaseType   : Database: jdbc:postgresql://<newdb>.db.elephantsql.com:5432/<newuser> (PostgreSQL 13.4)
----
* Remove old instance after some time to free resources


== Calculate discance between points using psql earth_distance function

earthdistance is also available in free ElephantSQL Edition, as opposed to PostGIS. See also https://hashrocket.com/blog/posts/juxtaposing-earthdistance-and-postgis[Comparing PostGIS and PostgreSQL's earthdistance]

. select in descending order by distance to a particular place (2nd arg), convert to km
[source,sql]
----
select name, ROUND( earth_distance(
               ll_to_earth(coordinates[2], coordinates[1]), -- lat, lon
               ll_to_earth(50.615653,6.437973)
           )::numeric / 1000)  AS distance FROM location ORDER BY distance DESC
----


== DB Resources to check

* Don't load all attributes for summary: https://vladmihalcea.com/the-best-way-to-lazy-load-entity-attributes-using-jpa-and-hibernate/[The best way to lazy load entity attributes using JPA and Hibernate]
* https://stackoverflow.com/questions/18896329/export-data-from-dynamodb[export-data-from-dynamodb]
* https://tapoueh.org/blog/2018/04/postgresql-data-types-arrays/[Hashtags as Arrays,Indexing PostgreSQL Arrays for Statistics and Profit - VERY GOOD!!!!]
* https://dba.stackexchange.com/questions/20974/should-i-add-an-arbitrary-length-limit-to-varchar-columns[Should I add an arbitrary length limit to VARCHAR columns?]
